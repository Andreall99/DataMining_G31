{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expore and Cleanup\n",
    "and also add some features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np  \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "import sys\n",
    "sys.path.append('../Functions')\n",
    "import CleanUp as p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '../Data/DM2425_ABCDEats_DATASET.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "shape_of_df = df.shape\n",
    "shape_of_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 count the Nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_nans = df.isnull().sum()\n",
    "x_xis = number_of_nans.index.tolist()\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.xticks(rotation=90)\n",
    "plt.ylabel('Number of NaNs in raw data')\n",
    "plt.title('Number of NaNs in each column')\n",
    "plt.bar(x=x_xis, height=number_of_nans, color='mediumaquamarine', edgecolor='dimgray', linewidth=0.8)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_nans.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Check for Duplicates in the primary key\n",
    "\n",
    "by the shape of the dataset the primary key should be customer_id, as such every value in this column should be unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "primary_key = 'customer_id'\n",
    "unique_values = df[primary_key].unique().shape\n",
    "n_rows = df[primary_key].shape [0]\n",
    "if unique_values != n_rows:\n",
    "    print('oh no! there are repetitions!')\n",
    "else:\n",
    "    print(\"all good! no repetitions!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find repeated customer_id\n",
    "repetitions = df[primary_key].value_counts()\n",
    "#keep only the customer_id that are repeated\n",
    "repetitions = repetitions[repetitions > 1]\n",
    "repetitions = repetitions.index\n",
    "repetitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for customer_id in repetitions:\n",
    "    rep_df = df[df[primary_key] == customer_id]\n",
    "    s = rep_df.shape\n",
    "    s1 = 0\n",
    "    for i in range(s[1]):\n",
    "        s1 += rep_df.iloc[:,i].unique().shape[0]\n",
    "    print(s1 - s[1])\n",
    "    # remove ont of the repeated  primary keys\n",
    "    if s1 - s[1] == 0:\n",
    "        df = df.drop(rep_df.index[0])\n",
    "        print('dropped repeated customer {p}'.format( p = customer_id))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['first_order'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"rows: \\t{p1} \\nclients:{p2}\".format( p1 = df.shape [0],\n",
    "                                        p2 = df[primary_key].unique().shape[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Non Numerical Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_numerical_columns = df.select_dtypes(include=['object']).columns.tolist()\n",
    "non_numerical_columns.remove(primary_key)\n",
    "print(non_numerical_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in non_numerical_columns:\n",
    "    print(f'{col}: {df[col].unique()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 customer_region\n",
    "Geographic region where the customer is located."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['customer_region'].unique()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.1 deal with missing values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['customer_region'] == '-', 'customer_region'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['customer_region'].unique()  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1.2 exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_count_dis = df['customer_region'].value_counts()\n",
    "region_percentage = region_count_dis / region_count_dis.sum() * 100\n",
    "print(region_percentage)\n",
    "region_nan = df['customer_region'].isnull().sum()\n",
    "print(region_nan/df.shape[0]*100)\n",
    "\n",
    "#order region_nan by alphabetical order\n",
    "x = zip(list(region_count_dis.index),list(region_count_dis.values))\n",
    "x = sorted(x, key=lambda x: x[0])\n",
    "region_count = dict(x)\n",
    "region_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjusted colors\n",
    "colors = ['lightsalmon', 'mediumaquamarine', 'tomato','lightsalmon', 'mediumaquamarine','tomato' ,'mediumaquamarine',  'tomato']\n",
    "\n",
    "# Configuring the pie chart with labels and highlighting the most relevant slice\n",
    "plt.figure(figsize=(20, 10))  # Setting figure size\n",
    "plt.pie(region_count_dis,\n",
    "        labels=region_count.keys(),\n",
    "        colors=colors,\n",
    "        startangle=90,  # Rotate the start of the pie chart\n",
    "        wedgeprops={'edgecolor': 'white', 'linewidth': 2})  # Creating the pie chart with black and thick edges\n",
    "plt.title('Regions distribution')  # Setting the title\n",
    "plt.show()  # Displaying the plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjusted colors\n",
    "colors = ['lightsalmon', 'lightsalmon', 'lightsalmon', 'mediumaquamarine', 'mediumaquamarine', 'tomato', 'tomato', 'tomato']\n",
    "\n",
    "# Configuring the pie chart with labels and highlighting the most relevant slice\n",
    "plt.figure(figsize=(20, 10))  # Setting figure size\n",
    "plt.pie(region_count.values(),\n",
    "        labels=region_count.keys(),\n",
    "        colors=colors,\n",
    "        startangle=90,  # Rotate the start of the pie chart\n",
    "        wedgeprops={'edgecolor': 'white', 'linewidth': 2})  # Creating the pie chart with black and thick edges\n",
    "plt.title('Regions distribution')  # Setting the title\n",
    "plt.show()  # Displaying the plot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.barplot(region_count_dis,color='mediumaquamarine')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 last_promo\n",
    "The category of the promotion or discount most recently used by the\n",
    "custome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.1 deal with missing values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['last_promo'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a new boolean column the is called has_promo \n",
    "\n",
    "df['has_promo'] = df['last_promo'] != 'No_Promo'\n",
    "df['has_promo'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2.2 exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjusted colors\n",
    "colors = ['lightsalmon', 'mediumaquamarine', 'tomato', 'darkturquoise']\n",
    "\n",
    "# Configuring the pie chart with labels and highlighting the most relevant slice\n",
    "plt.figure(figsize=(10, 5))  # Setting figure size\n",
    "plt.pie(df.last_promo.value_counts(), \n",
    "        colors=colors, \n",
    "        labels=df.last_promo.value_counts().index,  # Labels for each slice\n",
    "        autopct='%1.1f%%',  # Percentages on each slice\n",
    "        startangle=140,  # Starting angle for better layout\n",
    "        explode=(0.1, 0, 0, 0),  # Highlight the first slice (adjust as needed)\n",
    "        wedgeprops={'edgecolor': 'gray'})  # Gray borders for contrast\n",
    "\n",
    "# Chart title\n",
    "plt.title(\"Promotion Distribution\", fontsize=16, fontweight='bold', color='darkslategray', pad=20)\n",
    "\n",
    "# Displaying the chart\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 payment_method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['payment_method'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_pay = df['payment_method'].value_counts()\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.bar(x=total_pay.index, height=total_pay.values, color='mediumaquamarine', edgecolor='dimgray', linewidth=0.8)\n",
    "plt.title('Payment Method Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_pay"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Numerical Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns = df.select_dtypes(include=['float64', 'int64']).columns.tolist()\n",
    "print(numerical_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 vendor_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['vendor_count'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df['vendor_count'], bins = 50, color = 'mediumaquamarine', edgecolor = 'dimgray')\n",
    "\n",
    "plt.xlabel('Vendor Count')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Vendor Count Distribution')\n",
    "#adda  line to shw the outliers\n",
    "plt.axvline(df['vendor_count'].mean(), color='k', linestyle='dashed', linewidth=1)\n",
    "Q1 = df['vendor_count'].quantile(0.25)\n",
    "Q3 = df['vendor_count'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "plt.axvline(Q3 + 1.5 * IQR, color='r', linestyle='dashed', linewidth=1)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 product_count\n",
    "Total number of products the customer has ordered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df['product_count'], bins = 50, color = 'mediumaquamarine', edgecolor = 'dimgray')\n",
    "\n",
    "plt.xlabel('product Count')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('product Count Distribution')\n",
    "#adda  line to shw the outliers\n",
    "plt.axvline(df['product_count'].mean(), color='k', linestyle='dashed', linewidth=1)\n",
    "Q1 = df['product_count'].quantile(0.25)\n",
    "Q3 = df['product_count'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "plt.axvline(Q3 + 1.5 * IQR, color='r', linestyle='dashed', linewidth=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 is_chain\n",
    "Indicates whether the customer’s order was from a chain restaurant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.1 exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['is_chain'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df['is_chain'], bins = 50, color = 'mediumaquamarine', edgecolor = 'dimgray')\n",
    "\n",
    "plt.xlabel('is_chain')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('is_chain Distribution')\n",
    "#adda  line to shw the outliers\n",
    "plt.axvline(df['is_chain'].mean(), color='k', linestyle='dashed', linewidth=1)\n",
    "Q1 = df['is_chain'].quantile(0.25)\n",
    "Q3 = df['is_chain'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "plt.axvline(Q3 + 1.5 * IQR, color='r', linestyle='dashed', linewidth=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.2 check for consistency with product_count and vendor_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"product_count-->\",(df['product_count'] - df['is_chain']).min())\n",
    "print(\"vendor_count-->\",(df['vendor_count'] - df['is_chain']).min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Recount the missing values after the mild preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for missing values\n",
    "missing_values = df.isnull().sum()\n",
    "missing_values[missing_values > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_nans = df.isnull().sum()\n",
    "x_xis = number_of_nans.index.tolist()\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.xticks(rotation=90)\n",
    "plt.ylabel('Number of NaNs mild ')\n",
    "plt.title('Number of NaNs in each column')\n",
    "plt.bar(x=x_xis, height=number_of_nans, color='mediumaquamarine', edgecolor='dimgray', linewidth=0.8)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FYI,there are missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Build New Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_fetures_list = []\n",
    "# is there  a naming convention for new features?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 customer_city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['customer_city'] = df['customer_region'].str[0]\n",
    "df['customer_city'].unique()\n",
    "new_fetures_list.append('customer_city')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_count = df['customer_city'].value_counts()\n",
    "city_percentage = city_count / city_count.sum() * 100\n",
    "print(city_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "colors = ['lightsalmon', 'mediumaquamarine', 'tomato']\n",
    "plt.pie(city_percentage, labels = city_percentage.index, autopct='%1.1f%%', colors= colors)\n",
    "plt.title('City distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(city_count,color='mediumaquamarine')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 used_promo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['used_promo']= df['last_promo'] != '-'\n",
    "new_fetures_list.append(\"used_promo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 order_count\n",
    "The total amount of orders each customer made. <br>\n",
    "it can either be calculated by summung the DOW orders or the HR orders, let's see if the result is consistent <br>\n",
    "as we have seen at teh beginning, there are nans in the HR, so it's eay to expecr a discrepancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOW_col = [col for col in df.columns if col.startswith('DOW')]\n",
    "HR_col = [col for col in df.columns if col.startswith('HR')]\n",
    "DOW_col_sum = df[DOW_col].sum(axis=1)\n",
    "HR_col_sum = df[HR_col].sum(axis=1)\n",
    "Delta_DOW_HR = DOW_col_sum-HR_col_sum\n",
    "Delta_DOW_HR.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the values are not consistent <br>\n",
    "But we can notice that the values are always positive! <br>\n",
    "Since there are also missing values in HR, it's possible to assume that HR is underestimating and we can fill the missing values with the difference\n",
    "meanwhile the new feature Total_Orders will be made using the DOW data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['order_count'] = DOW_col_sum\n",
    "HR_col_from1 = HR_col.copy()\n",
    "HR_col_from1.remove('HR_0')\n",
    "HR_col_from1_sum = df[HR_col_from1].sum(axis=1)\n",
    "df['HR_0'] = DOW_col_sum - HR_col_from1_sum\n",
    "\n",
    "df[HR_col].sum().sum() - df[DOW_col].sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### check for consistency with is_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"order_count -->\",(df['order_count'] - df['is_chain']).min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "there are cases that are values of is_chain tha are bigger than teh number of orders and product count or the vendor count, this gives problem reagrding teh interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 avg_product_by_Order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['avg_product_by_order'] = p.safe_divide(df['product_count'],df['order_count'])\n",
    "new_fetures_list.append(\"avg_product_by_order\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 delta_day_order\n",
    "shows the time passed beween the first order and the last order\n",
    "-- note:\n",
    "we could adjust the parameter by using the highest day for the last order in the dataframe as today"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['delta_day_order'] = df['last_order'] - df['first_order'] + 1\n",
    "new_fetures_list.append('delta_day_order')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 tot_value_cui\n",
    "shows the total amunt of money spent on the app across all options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cui_columns = [col for col in df.columns if col.startswith('CUI')]\n",
    "df['tot_value_cui'] = df[cui_columns].sum(axis=1)\n",
    "new_fetures_list.append('tot_value_cui')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.7 order_freq\n",
    "more insightful informations about our customers habits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['order_freq'] = p.safe_divide(df['order_count'], df['delta_day_order'])\n",
    "new_fetures_list.append('order_freq')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.8 value_freq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['value_freq'] =p.safe_divide(df['tot_value_cui'], df['delta_day_order'])\n",
    "new_fetures_list.append('value_freq')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.9 product_freq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['product_freq'] = p.safe_divide(df['product_count'], df['delta_day_order'])\n",
    "new_fetures_list.append('product_freq')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.10 avg_order_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['avg_order_value'] = p.safe_divide(df['tot_value_cui'], df['order_count'])\n",
    "new_fetures_list.append('avg_order_value')\n",
    "df['avg_order_value'] = np.where(df['product_count'] != 0, df['tot_value_cui'] / df['product_count'], 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.11 avg_product_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['avg_product_value'] = p.safe_divide(df['tot_value_cui'], df['product_count'])\n",
    "new_fetures_list.append('avg_product_value')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.12 is_chain_bool (not added)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['is_chain_bool'] = df['is_chain'] != 0\n",
    "new_fetures_list.append(\"is_chain_bool\")\n",
    "x = df[['is_chain_bool','order_count','vendor_count','product_count']]\n",
    "x_true = x[x['is_chain_bool']]\n",
    "print(x_true['is_chain_bool'].unique())\n",
    "print(x_true['order_count'].min())\n",
    "print(x_true['vendor_count'].min())\n",
    "print(x_true['product_count'].min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.13 our new features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(new_fetures_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[new_fetures_list].describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for missing values\n",
    "missing_values_new_features = df[new_fetures_list].isnull().sum()\n",
    "missing_values_new_features = [missing_values > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot #check for missing values\n",
    "missing_values_new_features = df[new_fetures_list].isnull().sum()\n",
    "missing_values_new_features = missing_values_new_features[missing_values_new_features > 0]\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.bar(missing_values_new_features.index, missing_values_new_features, color='mediumaquamarine', edgecolor='dimgray', linewidth=0.8)\n",
    "plt.xticks(rotation=90)\n",
    "plt.ylabel('Number of NaNs')\n",
    "plt.title('Number of NaNs in each column')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check if I made a mess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_inf_counts_list = []\n",
    "\n",
    "for new_feture in new_fetures_list:\n",
    "    nan_count = df[new_feture].isna().sum()\n",
    "    inf_count = df[new_feture].isin([np.inf, -np.inf]).sum()\n",
    "    nan_inf_counts = {\n",
    "        'feature': new_feture,\n",
    "        'nan_count': nan_count,\n",
    "        'inf_count': inf_count\n",
    "    }\n",
    "    \n",
    "    nan_inf_counts_list.append((new_feture, nan_count, inf_count))\n",
    "    \n",
    "df_naninf = pd.DataFrame(nan_inf_counts_list, columns=['feature', 'nan_count', 'inf_count'])\n",
    "df_naninf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[new_fetures_list[0:11]].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['customer_city'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['used_promo'].describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataMinig",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
